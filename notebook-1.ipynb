{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3393057-ea06-4f2d-94c7-9697fccd3a41",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9397067b9282bf77aa677b093849d83d",
     "grade": false,
     "grade_id": "cell-8f51681d0010e7ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "***DISCLAIMER (Read this carefully)***\n",
    "\n",
    "Before you turn this assignment in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel\n",
    "Restart) and then run all cells (in the menubar, select Cell\n",
    "Run All). Do NOT add any cells to the notebook!\n",
    "\n",
    "Do not forget to submit both the notebook AND the files in the data/ subfolder according to the CoC!\n",
    "Make sure you fill in any place that says YOUR CODE HERE or YOUR ANSWER HERE , as well as your name and group below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "981a73c8-4cde-4ea3-976a-8cce8ce3207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the libraries you are allowed to use for this assignment\n",
    "# If any of those libraries are not present in your jupyter instance, install them by using !pip install [library-name]!\n",
    "import xmltodict\n",
    "import csv\n",
    "import json\n",
    "import pytest\n",
    "import requests\n",
    "import codecs\n",
    "import math\n",
    "import re\n",
    "import requests\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b4ced-9b69-4c8e-a7d0-12265cc28eea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccbfb02fdc67dc903abb412ab000bf72",
     "grade": false,
     "grade_id": "cell-01518f30645ea1ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Assignment 2 (Group)\n",
    "When carrying out a Data-Science project, screening and selecting appropriate data sources for the tasks at hand comes at the beginning. This assignment is about accessing and characterising potential data sources in teams of three. The teams have been randomly assigned. BEWARE! In Assignment 5, you will be asked to provide answers to those questions. Make sure that combining the two datasets makes sense from an analytical perspective!\n",
    "\n",
    "-----\n",
    "## Step 0 (2 points)\n",
    "\n",
    "Find two data sets online (from one or several sources) that would be interesting to combine and create ***data citations*** as Python dictionaries. \n",
    "\n",
    "The data sets should fulfill the following requirements:\n",
    "\n",
    "* Each data set must have a different file format (either CSV, XML, or JSON), please choose\n",
    "  - one CSV file (dataset1) \n",
    "  - and one JSON or XML file (dataset2)\n",
    "\n",
    "* The two datasets should not be two variations of each other (i.e. simply the same dataset for two different regions or timeframes or from the same source just in two different formats)\n",
    "* Workable data-set sizes: The selected or extracted data sets should have thousands of entries (>= 1000), but not more than (<=) 10000 entries. Be \"entries we mean rows or distinguishable key-value pairs). If larger, use an excerpt from the original data set. Justify in detail the extraction criteria in the markdown cell below and \n",
    "  1) add the code used for the extraction in the code cell or describe how you filtered the sample  \n",
    "  2) make the extracted dataset also available at a downloadable URL (for instance in a Github repository, [here](https://raw.githubusercontent.com/AxelPolleres/simple_dataset_sharing_repo/main/test.csv)'s an example)\n",
    "  3) name the new `resourceURL` in the data citation.\n",
    "* You may start from (but you are not limited to) the resource collections hinted at [in the Unit 2 slides](https://datascience.ai.wu.ac.at/ws21/dataprocessing1/unit2.html#slide-53).\n",
    "\n",
    "* Important: The use of datasets from kaggle.com and other curated collections of datasets with accompanying tutorials on processing and analysis (as highlighted to you in Unit 2) isÂ **discouraged**. You are required to use **primary data sources**: This is mainly because we want you to work on data sets that have not been processed with some analysis in mind, so that you show that you can handle (messy) data sets harvested on the brownfields of Data Science. Besides, such curated datasets have been repeatedly used in ready-made case and tutorial work, which makes it basically impossible for us to establish whether your submissions are genuine contributions of yours.Â There is one viable option:Â Work backwards from the Kaggle data set to the original data source, obtain updated data from there, and start from there.\n",
    "\n",
    "\n",
    "* Please adhere to the CoC.\n",
    "\n",
    "[Data citations](http://blogs.nature.com/scientificdata/2016/07/14/data-citations-at-scientific-data/) must contain the following details:\n",
    "- creator: provider organisation / author(s) of the data set, e.g. \"Zentralanstalt fÃ¼r Meteorologie und Geodynamik (ZAMG)\"\n",
    "- catalogName: Names of the data repository and/or the Open Data portal used, e.g. Open Data Ã–sterreich\"\n",
    "- catalogURL: URL of th repository / portal, e.g. \"https://www.data.gv.at/\"\n",
    "- datasetID: (specific to the data repository), e.g. \"https://www.data.gv.at/katalog/dataset/zamg_meteorologischemessdatenderzamg\"\n",
    "- resourceURL: a URL where the CSV, XML or JSON file can be downloaded, e.g. \"https://www.football-data.co.uk/new/JPN.csv\"\n",
    "- pubYear: Dataset publication year, i.e. since when it is published, e.g. \"2012\"\n",
    "- lastAccessed: when have you last accessed the dataset (i.e. datetime of accessing, obtaining a copy of the data set) in ISO Format? e.g. \"2021-03-08T13:55:00\"\n",
    "\n",
    "One final note: as mentioned above, if you want to use a repository for your file download (e.g. github), you are allowed to do that. The most important part is that the URL can be accessed stably for each dataset you have chosen. \n",
    "\n",
    "Store the data citation in a dictionary for each of the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ac2b05-1102-4cf7-96a3-f1ec47459ece",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b6ee8b15f725340d21f67892d57f1cf",
     "grade": true,
     "grade_id": "cell-cea2669d70d8d76a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "dataset1= {\n",
    "    \"creator\" : \"Michael Ross and Paasha Mahdavi\" ,\n",
    "    \"catalogName\" : \"Harvard Dataverse\" ,\n",
    "    \"catalogURL\" : \"https://dataverse.harvard.edu/\" ,\n",
    "    \"datasetID\" : \"https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ZTPW0Y#\" ,\n",
    "    \"resourceURL\" : \"https://raw.githubusercontent.com/alexgradev/wu-dp1/refs/heads/main/Ross-Mahdavi%20Oil%20and%20Gas%201932-2014.csv\"  ,\n",
    "    \"pubYear\" : \"2015\"  ,\n",
    "    \"lastAccessed\" : \"2025-03-21T10:45:30\"  ,\n",
    "}\n",
    "\n",
    "dataset2= {\n",
    "    \"creator\" : \"Group 8 / 4891\" ,\n",
    "    \"catalogName\" : \"Yahoo Finance Historical Stock Data\" ,\n",
    "    \"catalogURL\" : \"https://finance.yahoo.com/quote/XOM/history\" ,\n",
    "    \"datasetID\" : \"xom_stock_1970_2010\" ,\n",
    "    \"resourceURL\" : \"https://raw.githubusercontent.com/alexgradev/wu-dp1/refs/heads/main/xom_data.json\"  ,\n",
    "    \"pubYear\" : \"2025\"  ,\n",
    "    \"lastAccessed\" : \"2025-03-21T10:45:30\"  ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "852966b3-7ce6-47e0-a879-2de74b756861",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12168528df39434b1523d55f040752fe",
     "grade": true,
     "grade_id": "cell-d3cc293b6207d1c7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import sys\n",
    "import os\n",
    "\n",
    "assert type(dataset1) == dict\n",
    "assert type(dataset2) == dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c1bfa-decc-4711-83c1-87c761bda55e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12991e2a6ff07860ffd880d80927f39e",
     "grade": false,
     "grade_id": "cell-a34ab569805a650e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Please answer the questions in the cell below\n",
    "\n",
    "Use the following structure for your answer below:\n",
    "\n",
    "Data set 1\n",
    "\n",
    "(Describe the source and the general content of the dataset and why you chose it)\n",
    "\n",
    "Data set 2\n",
    "\n",
    "(Describe the source and the general content of the dataset and why you chose it)\n",
    "\n",
    "Project ideas\n",
    "\n",
    "(Describe in your own words, which kind of tasks could be addressed by combining the selected data sets, esp. how the two data sets fit together and what complementary information they contain; Formulate a question that could be potentially answered by combining data from both datasets; how could the data sets be combined exactly? 250 words max. BEWARE! In Assignment 5, you will be asked to provide answers to those questions. Make sure that combining the two datasets makes sense from an analytical perspective!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04cd31-a41c-4d42-b756-87567ed08ee8",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25e589c21292c28ecbe9193e15daa7b9",
     "grade": true,
     "grade_id": "cell-9bc09f21e0c42050",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Data set 1\n",
    "\n",
    "The Oil and Gas Dataset provides annual country-level data on oil production, prices, and values from 1932 to 2014. The sources used to develop the data set are institutions like the EIA and World Bank. It holds information about the country, the year, oil and gas production in metric tons, oil and gas prices in nominal USD and constant 2000 USD, etc. We chose this data set because we can aggregate the countries by year to get the total worldwide oil and gas production and price per year.\n",
    "\n",
    "Data set 2\n",
    "\n",
    "We downloaded the data using R's package \"quantmod\" and then we exported it into a JSON file with the help of the \"jsonlite\" package. Although we initially tried to extract daily data using Python the Alpha Vantage API restricts daily data to premium users and \"yfinance\" did not return a complete historical range. JSON file holds daily data for the ExxonMobil stock price as well as the close price adjusted for stock splits and dividends.\n",
    "\n",
    "Project ideas\n",
    "\n",
    "We are interested in analysing how global oil and gas production and prices impact oil company stock performance. Aggregating the stock data annually allows alignment by year with the macroeconomic oil data set. This allows us to compare financial performance metrics, such as annual returns and volatility, with changes in production and price. Our research question would be: \"Does global oil market data have predictive power for oil company stock performance?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43ce55-9c0b-44b2-a833-8e4e107175da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4c6631a22555c4c784b89e218ae1012",
     "grade": false,
     "grade_id": "cell-426859b26b9c84e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------\n",
    "## Step 1 - File Access (3 points)\n",
    "\n",
    "Write a Python function `accessData` that takes the dataset dictionary created in step 0 as an input and returns an extended dictionary including following additions:\n",
    "\n",
    "* Write code that accesses the dataset from its `resourceURL` using the python `requests` package:\n",
    " * detects whether it's and XML, CSV or JSON file by\n",
    "     * checking whether the download URL **ends** with suffix \"xml\", \"json\", \"csv\" (in either upper- or lowercase)\n",
    "     * checking whether the \"Content-Type\" HTTP header field contains information about the format, hinting on XML, JSON or CSV, i.e., check whether the substring XML, JSON or CSV appears in the \"Content-Type\" header in either upper- or lowercase. \n",
    " * Detects the file size from the HTTP header (converted to KB) of each data set, clearly documenting your actions (e.g. through commented code).\n",
    "\n",
    "The result of the code below should extend your dictionaries `dataset1` and `dataset2` with two keys named \n",
    "* `\"detectedFormat\"` (which has one of the following values: `\"XML\"`, `\"JSON\"`, `\"CSV\"`, or `\"unknown\"`, if nothing could be detected from checking the suffix or HTTP header, or if the information in both was inconsistent)\n",
    "* and `\"filesizeKB\"` which contains the filesize in KB (Conversion should be done accordingly to decimal SI prefixes) from the number of bytes in the header-information. If there is no respective header information return 0.\n",
    "* If the detected format is `\"unknown\"`, the expected filesize to be returned is also 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a06da511-204d-4316-bc92-507835acbe27",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a1ca537ab893786c9e466e4490d8a8b",
     "grade": false,
     "grade_id": "cell-87173edcb1445261",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Results==========\n",
      "Dataset 1:\n",
      " Detected Format: CSV\n",
      " File Size: 1025.0 KB\n",
      "Dataset 2:\n",
      " Detected Format: JSON\n",
      " File Size: 209.04 KB\n"
     ]
    }
   ],
   "source": [
    "def accessData(datadict):\n",
    "    url = datadict[\"resourceURL\"]\n",
    "    \n",
    "    r = requests.head(url) \n",
    "    headerDict=r.headers\n",
    "\n",
    "    if url.lower().endswith(\".xml\"):\n",
    "        url_suffix = \"XML\"\n",
    "    elif url.lower().endswith(\".json\"):\n",
    "        url_suffix = \"JSON\"\n",
    "    elif url.lower().endswith(\".csv\"):\n",
    "        url_suffix = \"CSV\"\n",
    "    else:\n",
    "        url_suffix = \"unknown\"\n",
    "\n",
    "    content_type = headerDict.get(\"Content-Type\", \"\").lower()\n",
    "    if \"xml\" in content_type:\n",
    "        http_header = \"XML\"\n",
    "    elif \"json\" in content_type:\n",
    "        http_header = \"JSON\"\n",
    "    elif \"csv\" in content_type:\n",
    "        http_header = \"CSV\"\n",
    "    else:\n",
    "        http_header = \"unknown\"\n",
    "        \n",
    "    if url_suffix == http_header and url_suffix != \"unknown\":\n",
    "        detected_format = url_suffix\n",
    "    elif url_suffix != \"unknown\" and http_header == \"unknown\":\n",
    "        detected_format = url_suffix\n",
    "    elif http_header != \"unknown\" and url_suffix == \"unknown\":\n",
    "        detected_format = http_header\n",
    "    else:\n",
    "        detected_format = \"unknown\"\n",
    "        \n",
    "    if \"Content-Length\" in headerDict and detected_format != \"unknown\":\n",
    "        size_bytes = int(headerDict[\"Content-Length\"])\n",
    "        filesize_kb = round(size_bytes / 1000, 2)\n",
    "    else:\n",
    "        filesize_kb = 0\n",
    "\n",
    "    datadict[\"detectedFormat\"] = detected_format\n",
    "    datadict[\"filesizeKB\"] = filesize_kb\n",
    "    \n",
    "    print(headerDict[\"Content-Length\"], headerDict[\"Accept-Ranges\"])\n",
    "    print(content_type)\n",
    "            \n",
    "    return datadict\n",
    "\n",
    "\n",
    "print(\"==========Results==========\")\n",
    "\n",
    "print(\"Dataset 1:\")\n",
    "print(\" Detected Format:\",dataset1[\"detectedFormat\"])\n",
    "print(\" File Size:\", dataset1[\"filesizeKB\"], \"KB\")\n",
    "\n",
    "print(\"Dataset 2:\")\n",
    "print(\" Detected Format:\",dataset2[\"detectedFormat\"])\n",
    "print(\" File Size:\",dataset2[\"filesizeKB\"], \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ba078d8-b700-4cb8-8a18-4a2fa86dc210",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fbfcaf8282114a8d61c3cae0cea5ee4",
     "grade": true,
     "grade_id": "cell-09b529ecf9606ac6",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025001 bytes\n",
      "text/plain; charset=utf-8\n",
      "209038 bytes\n",
      "text/plain; charset=utf-8\n"
     ]
    }
   ],
   "source": [
    "# Basic tests to see if your solution meets the foundational demands described in the task description\n",
    "dataset1 = accessData(dataset1)\n",
    "dataset2 = accessData(dataset2)\n",
    "if dataset1[\"detectedFormat\"] not in [\"XML\", \"JSON\", \"CSV\", \"unknown\"]:\n",
    "    raise AssertionError\n",
    "if dataset2[\"detectedFormat\"] not in [\"XML\", \"JSON\", \"CSV\", \"unknown\"]:\n",
    "    raise AssertionError\n",
    "\n",
    "assert isinstance(dataset1[\"filesizeKB\"],(int, float)) == True\n",
    "assert isinstance(dataset2[\"filesizeKB\"],(int, float)) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134ce01-5e26-4fd9-b7be-c83135572eea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a790e5e6ab835612be43bf7d51d7033",
     "grade": true,
     "grade_id": "cell-1c560982a2f27ace",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Edit this cell or remove it, and you shall perish, meow! ðŸ˜¼âš¡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60a646-215e-4b49-8c2d-fbccbef78af4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e2767aef997a735d1d876e1b23e6169",
     "grade": true,
     "grade_id": "cell-6f7cbd4186584572",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I know you are reading this, there is no help here, no hope. Also, do not delete me please :3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa69593-670f-4b2c-b5d0-1c70c9970b92",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "612a790836aa21e3a63991348694e9b4",
     "grade": false,
     "grade_id": "cell-dcd3aa38b0b6d216",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Please answer the questions in the cell below\n",
    "\n",
    "#### Please explain your findings, using the following structure for your answer below (in \"other remarks\" you can explain, for instance, why you think your code did not detect the correct format, if needed)\n",
    "\n",
    "Data set 1\n",
    "\n",
    "(format, size, other remarks)\n",
    "\n",
    "Data set 2\n",
    "\n",
    "(format, size, other remarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ffd91-c334-43fd-aa68-ae9aeb9ae24b",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25ee6f9a55d5499eae679e146a2fb0c3",
     "grade": true,
     "grade_id": "cell-40248ad63aa2baea",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26a4ed-ce75-4a64-8c94-0eff3cb8de7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8ba2987efce440ec7e6f4d4857bd88e",
     "grade": false,
     "grade_id": "cell-c236c8ec72c4dded",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "## Step 2  (5 points) - Format Validation\n",
    "\n",
    "Establish that the two data files obtained are well-formed according to the detected data format (CSV, JSON, or XML). That is, the syntax used is valid according to accepted syntax definitions. Are there any violations of well-formedness?\n",
    "\n",
    "\n",
    "Proceed as follows (for each data file, in turn): according to the \"suspected\" data format from Step 1:\n",
    "\n",
    "  1. Use an _online validator_ for CSV, XML, and JSON, respectively, to confirm whether the files you downloaded in Step 1 are well-formed for the respective file format, document your findings and modify the file as described: \n",
    "\n",
    "   a. **Case 1**: no well-formedness errors were detected: \n",
    "    * Generally describe at least 3 well-formedness checks that your data sets, depending on its \"suspected\" format (against the background knowledge of Unit 2) should fulfill;\n",
    "    * Store a local copy of the file called `data_notebook-[notebook-nr.]_[name].[file extension]` in the `data/` subfolder\n",
    "    * Create another local copy of your data file called `data_notebook-[notebook-nr.]_[name]-invalid.[file extension]` and introduce a selected well-formedness violation (one occurrence) therein;\n",
    "    * document that the online validator you used finds the error you introduced\n",
    "\n",
    "   b. **Case 2**: well-formedness errors occurred:\n",
    "    * Document the occurrences by printing out the error message and describe the types of well-formedness violation that were reported to you.\n",
    "    * Store a local copy called `data_notebook-[notebook-nr.]_[name]-invalid.[file extension]`  in the `data/ subfolder`\n",
    "    * Create another local copy called `data_notebook-[notebook-nr.]_[name].[file extension]`, of your data file that fixes the well-formedness violations therein manually.  \n",
    "    \n",
    "**Please note that the datasets in the `data/` subfolder are for documentation only. Do not access those for subsequent steps!**\n",
    "    \n",
    "\n",
    "  2. Write a Python function `parseFile(datadict, format)` that that accesses the dataset from its `resourceURL`. The dataset should then be checked accordingly the given parser for the parameter `format` to check the following:\n",
    "     * CSV: Returns `True`, if a consistent delimiter out of `\",\",\";\",\"\\t\"` can be detected, such that each row has the same (> 1) number of elements, otherwise False\n",
    "     * JSON: Returns `True` if the file can be parsed with the `json` package, catching any parsing exceptions.\n",
    "     * XML: Returns `True` if the file can be parsed with the `xmltodict` package, catching any parsing exceptions.\n",
    "     * Returns `False` if any other format is supplied by the parameter.\n",
    "     \n",
    "In order to handle parsing exceptions and errors from the used packages, you can use [catching exceptions](https://docs.python.org/3/tutorial/errors.html), such that the program does not simply fail to check whether the file is parseable as the format specified in `format`    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d77f70-6543-4aab-9306-010a706fd09b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "356da61d941023bc467b54542264c09d",
     "grade": false,
     "grade_id": "cell-57dc295d9edd354d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Please answer the questions in this cell\n",
    "\n",
    "### Use the following structure for your answer in the cell below to document **Step 2.1**:\n",
    "\n",
    "***Data set 1***\n",
    "\n",
    "*(validator used, validation results, describe the modification to fix the file or to create an invalid version of it)*\n",
    "\n",
    "***Data set 2***\n",
    "\n",
    "*(validator used, validation results, describe the modification to fix the file or to create an invalid version of it)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec87d67-75e8-4bc7-9502-f24598959a5e",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bdffe13535005452547b95c914f7071b",
     "grade": true,
     "grade_id": "cell-7326ff597819ce15",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5bfb28-0a4f-4fbe-a2ed-4d8e9c3d52d8",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4732c1de34a7254c7e8f92d1a8d6f72",
     "grade": false,
     "grade_id": "cell-e72d44bc996d8aaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parseFile(datadict, format):\n",
    "    # YOUR CODE FOR STEP 2.2 HERE\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5b307-c87b-4906-afc6-9c1febd645e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9281d46b50b1db2eb696cf556870930c",
     "grade": true,
     "grade_id": "cell-44a0730c406d4f1f",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This checks if your code returns true twice for either xml, json or csv for your datasets specifically.\n",
    "\n",
    "assert([parseFile(dataset1, \"XML\"),\n",
    "    parseFile(dataset1, \"JSON\"),\n",
    "    parseFile(dataset1, \"CSV\"),\n",
    "    parseFile(dataset2, \"XML\"),\n",
    "    parseFile(dataset2, \"JSON\"),\n",
    "    parseFile(dataset2, \"CSV\")].count(True)) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749dd2d7-e366-4cd9-8186-a1ac278e9e9f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f74ccd979eba3be80df1b3a134d0789a",
     "grade": true,
     "grade_id": "cell-c8199bfc375750df",
     "locked": true,
     "points": 3.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There will be consequences if you remove this cell, or even move this cell. Be wary of that <3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14967cf4-e8da-4e9a-90a9-752f1f441915",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a27a734c0b600b5516729b67f6e577d",
     "grade": false,
     "grade_id": "cell-c0772a5952f0b1fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "## Step 3 - Content analysis (5 points)\n",
    "\n",
    "Similar to the Python function `parseFile(datadict,format)` above, now create a new Python function `describeFile(datadict)` that analyses the given file according to the respective format detected in Step 1 and returns a dictionary containing the following information:\n",
    "\n",
    "* for CSV files: number of numeric (float) columns, number of rows, column index (from 0 to n) and row index of the entry which contains the largrst float value which is a round number (modulo 2 with a remainder of 0). Ensure to try to transform any entry to a numeric type to ensure no number is accidentely seen as a string. The resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfNumericColumns:\"  ...,\n",
    "       \"numberOfRows\":  ... ,\n",
    "       \"largestFloat\" : ... }\n",
    "    ```\n",
    "\n",
    "* for JSON files: number of distinct attribute names, nesting depth, length of the longest list appearing in an attribute value. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfAttributes:\" ... ,\n",
    "      \"nestingDepth\":  ... ,\n",
    "      \"longestListLength\" : ... }\n",
    "     ```\n",
    "\n",
    "  Here the `longestListLength` should be set to 0 if no list appears. [Nesting depth](https://www.tutorialspoint.com/find-depth-of-a-dictionary-in-python) is defined as follows: \n",
    "   * a flat list of atomic values has depth 0, a flat JSON object with only atomic attribute values has depth 1. \n",
    "   * a JSON attribute with another object as value (or another object as member of a list value!) increases the depth by 1\n",
    "   * and so on.\n",
    "\n",
    "\n",
    "* for XML files: number of different element and attribute a names (i.e. the sum of both), nesting depth, maximum numeric value in the dataset. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfElementsAttributes:\" ... ,\n",
    "      \"nestingDepth\":  ... ,\n",
    "      \"longestString\" : ... }\n",
    "     ```\n",
    "\n",
    "  Here the `longestString` should be set to \"\" if there are no String values present. Nesting depth is defined as the nesting depth of elements.\n",
    "  \n",
    "For files that cannot be parsed with respective given format, the function should simply return an empty dictionary (`{}`).\n",
    "\n",
    "##### Please ensure to keep the order of the elements as specified above! The test cases assume that your result has the same structure as the ones specified above. Basically this means for the csv e.g. that the first position should ALWAYS be the numberOfNumericColumns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7a03d-610f-4591-94c5-b3fe6af3517a",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e3f7bd8fbced4b87d03372a0266b509",
     "grade": false,
     "grade_id": "cell-2123d8521820ec726",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def describeFile(datadict):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e58d31-e57e-4ac6-84d3-48809e6b0d04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f1366f100e7999f4c277405ab2794ad",
     "grade": true,
     "grade_id": "cell-eba7f348525a45dd",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(len(describeFile(dataset1))) == 3\n",
    "assert(len(describeFile(dataset2))) == 3\n",
    "\n",
    "# Check your output\n",
    "print(describeFile(dataset1))\n",
    "print(describeFile(dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3964a3f4-838b-48db-b70a-1aa8dc045be4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f64ab1df5aa90e5d77c647cefa6cfbb1",
     "grade": true,
     "grade_id": "cell-179ad8edcdce23b21d",
     "locked": true,
     "points": 1.8,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Edit this cell or remove it, and you shall perish, meow! ðŸ˜¼âš¡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f794d334-83a6-43b4-9a2d-f5c58f8ef2f2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c23eb3b1d4f662bd6ddcf8d21e5c2e3",
     "grade": true,
     "grade_id": "cell-17969cee89805c39",
     "locked": true,
     "points": 1.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Edit this cell or remove it, and you shall perish, meow! ðŸ˜¼âš¡ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e1e37-e968-436f-ac91-a22154e6f32b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50254397eddaa1abb3f42df09cf17cd8",
     "grade": false,
     "grade_id": "cell-66aada55df321ea7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Please answer the questions\n",
    "\n",
    "***Final check:***\n",
    "\n",
    "Be sure to cross-check the results by\n",
    "1) manually inspecting your chosen dataset and\n",
    "2) comparing the results for plausibility against the results of your code... \n",
    "\n",
    "Describe your findings and use the following structure for your answer below:\n",
    "\n",
    "*Data set 1*\n",
    "\n",
    "(number and types of items etc., describe your findings)\n",
    "\n",
    "*Data set 2*\n",
    "\n",
    "(number and types of items etc., describe your findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bce1c-e495-4733-baa8-ddc2962f077f",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df18cdf1882599d295da8465485a5b1c",
     "grade": true,
     "grade_id": "cell-4709b3248c430b6a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
